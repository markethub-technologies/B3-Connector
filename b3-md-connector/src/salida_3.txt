
===== FILE: /workspaces/MarketHub.B3Connector/b3-md-connector/src/publishing/ZmqPublishConcentrator.hpp =====
        const uint64_t now = nowNsSteady();
        if (now >= nextHealth) {
          nextHealth = now + 5'000'000'000ull;
          emitHealth(now);
        }

        if (!didWork)
          std::this_thread::sleep_for(1ms);
      }

      // Drain opcional al final
      for (uint32_t sid = 0; sid < shardCount_; ++sid) {
        auto &q = *queues_[sid];
        while (q.try_pop(ev)) {
          (void)pub.sendMultipart(ev.topic, ev.topicLen, ev.bytes, ev.size);
          sentByShard_[sid].v.fetch_add(1, std::memory_order_relaxed);
        }
      }
    }

   private:
    std::string pubEndpoint_;
    uint32_t shardCount_{0};

    std::vector<std::unique_ptr<QueueT>> queues_;

    // Wrapper para poder usar atomics dentro de std::vector en libstdc++.
    //
    // Motivo:
    //   std::vector<std::atomic<T>> no es usable de forma portable en GCC/libstdc++,
    //   porque operaciones inocuas como reserve() instancian código que requiere
    //   que T sea copy/move constructible. std::atomic NO lo es, por diseño,
    //   lo que rompe la compilación aunque el vector esté vacío.
    //
    // Este wrapper hace a la métrica "copyable" copiando el valor de forma relaxed.
    // Es seguro para nuestro uso porque estos contadores son solo métricas,
    // no participan de sincronización ni de lógica de concurrencia del hot path.
    struct CopyableAtomicU64 {
      std::atomic<uint64_t> v;
      CopyableAtomicU64(uint64_t init = 0) noexcept : v(init) {}

      CopyableAtomicU64(const CopyableAtomicU64 &other) noexcept
          : v(other.v.load(std::memory_order_relaxed)) {}

      CopyableAtomicU64 &operator=(const CopyableAtomicU64 &other) noexcept {
        v.store(other.v.load(std::memory_order_relaxed), std::memory_order_relaxed);
        return *this;
      }
    };

    std::vector<CopyableAtomicU64> droppedByShard_;
    std::vector<CopyableAtomicU64> enqByShard_;
    std::vector<CopyableAtomicU64> sentByShard_;

    telemetry::SpdlogLogPublisher<kLogQueueCapacity> logger_;

    std::atomic<bool> running_{false};
    std::thread thread_{};
  };

} // namespace b3::md::publishing

===== FILE: /workspaces/MarketHub.B3Connector/b3-md-connector/src/publishing/PublishEvent.hpp =====
#pragma once
#include <cstdint>
#include <cstddef>

namespace b3::md::publishing {

  struct PublishEvent final {
    // HARD CAP global (longitud del topic, NO cantidad de tópicos)
    static constexpr size_t kMaxTopic = 128;
    static constexpr size_t kMaxBytes = 4096;

    // payload
    uint32_t size{0};

    // topic bytes (NO null-terminated)
    uint8_t topicLen{0};
    char topic[kMaxTopic]{};

    uint8_t bytes[kMaxBytes]{};
  };

} // namespace b3::md::publishing

===== FILE: /workspaces/MarketHub.B3Connector/b3-md-connector/src/core/MdPublishWorker.hpp =====
#pragma once

#include "SnapshotQueueSpsc.hpp"
#include "BookSnapshot.hpp"
#include "OrdersSnapshot.hpp"
#include "MboToMbpAggregator.hpp"

#include "../mapping/MdSnapshotMapper.hpp"
#include "../telemetry/SpdlogLogPublisher.hpp"
#include "../telemetry/LogEvent.hpp"
#include "../publishing/IPublishSink.hpp"
#include "../publishing/PublishEvent.hpp"
#include "../mapping/InstrumentTopicMapper.hpp"

#include <atomic>
#include <chrono>
#include <cstring>
#include <string>
#include <thread>
#include <cstddef>

namespace b3::md {

  class MdPublishWorker final {
   public:
    static constexpr size_t kQueueCapacity = 4096;
    static constexpr size_t kLogQueueCapacity = 1024;

    MdPublishWorker(uint32_t shardId, MdSnapshotMapper &mapper, publishing::IPublishSink &sink,
                    const b3::md::mapping::InstrumentTopicMapper &topicMapper)
        : shardId_(shardId), mapper_(mapper), sink_(sink), topicMapper_(topicMapper) {}

    MdPublishWorker(const MdPublishWorker &) = delete;
    MdPublishWorker &operator=(const MdPublishWorker &) = delete;

    void start() {
      bool expected = false;
      if (!running_.compare_exchange_strong(expected, true, std::memory_order_acq_rel))
        return;

      logger_.start();
      drainOnStop_.store(true, std::memory_order_relaxed);
      thread_ = std::thread([this] { run(); });
    }

    void stop(bool drain = true) {
      drainOnStop_.store(drain, std::memory_order_relaxed);
      running_.store(false, std::memory_order_release);
      if (thread_.joinable())
        thread_.join();
      logger_.stop();
    }

    bool tryEnqueue(const OrdersSnapshot &snapshot) noexcept {
      if (queue_.try_push(snapshot)) {
        enqueued_.fetch_add(1, std::memory_order_relaxed);
        return true;
      }
      dropped_.fetch_add(1, std::memory_order_relaxed);
      return false;
    }

    uint64_t enqueued() const noexcept { return enqueued_.load(std::memory_order_relaxed); }
    uint64_t dropped() const noexcept { return dropped_.load(std::memory_order_relaxed); }
    uint64_t published() const noexcept { return published_.load(std::memory_order_relaxed); }

   private:
    static uint64_t nowNsSystem() noexcept {
      const auto now = std::chrono::system_clock::now().time_since_epoch();
      return static_cast<uint64_t>(
          std::chrono::duration_cast<std::chrono::nanoseconds>(now).count());
    }

    // --- logging helpers (idénticos a los tuyos; los dejo tal cual para no tocarte behavior)
    void logStartup(uint64_t nowNs) noexcept {
      telemetry::LogEvent e{};
      e.tsNs = nowNs;
      e.level = telemetry::LogLevel::Info;
      e.component = telemetry::Component::Worker;
      e.code = telemetry::Code::Startup;
      e.shard = static_cast<uint16_t>(shardId_);
      (void)logger_.try_publish(e);
    }

    void logShutdown(uint64_t nowNs) noexcept {
      telemetry::LogEvent e{};
      e.tsNs = nowNs;
      e.level = telemetry::LogLevel::Info;
      e.component = telemetry::Component::Worker;
      e.code = telemetry::Code::Shutdown;
      e.shard = static_cast<uint16_t>(shardId_);
      e.arg0 = published_.load(std::memory_order_relaxed);
      e.arg1 = dropped_.load(std::memory_order_relaxed);
      (void)logger_.try_publish(e);
    }

    void emitHealth(uint64_t nowNs, uint64_t qsz, uint64_t dEnq, uint64_t dPub) noexcept {
      telemetry::LogEvent e{};
      e.tsNs = nowNs;
      e.level = telemetry::LogLevel::Health;
      e.component = telemetry::Component::Worker;
      e.code = telemetry::Code::HealthTick;
      e.shard = static_cast<uint16_t>(shardId_);
      e.arg0 = qsz;
      e.arg1 = ((dEnq & 0xFFFFFFFFull) << 32) | (dPub & 0xFFFFFFFFull);
      (void)logger_.try_publish(e);
    }

    void emitDrops(uint64_t nowNs, uint64_t deltaDrops, uint64_t totalDrops) noexcept {
      telemetry::LogEvent e{};
      e.tsNs = nowNs;
      e.level = telemetry::LogLevel::Health;
      e.component = telemetry::Component::Worker;
      e.code = telemetry::Code::Drops;
      e.shard = static_cast<uint16_t>(shardId_);
      e.arg0 = deltaDrops;
      e.arg1 = totalDrops;
      (void)logger_.try_publish(e);
    }

    void emitQueueSaturated(uint64_t nowNs, uint64_t qsz, uint64_t deltaDrops,
                            uint64_t totalDrops) noexcept {
      telemetry::LogEvent e{};
      e.tsNs = nowNs;
      e.level = telemetry::LogLevel::Health;
      e.component = telemetry::Component::Worker;
      e.code = telemetry::Code::QueueSaturated;
      e.shard = static_cast<uint16_t>(shardId_);
      e.arg0 = qsz;
      e.arg1 = ((deltaDrops & 0xFFFFFFFFull) << 32) | (totalDrops & 0xFFFFFFFFull);
      (void)logger_.try_publish(e);
    }

    void emitLogDrops(uint64_t nowNs, uint64_t deltaLogDrops, uint64_t totalLogDrops) noexcept {
      telemetry::LogEvent e{};
      e.tsNs = nowNs;
      e.level = telemetry::LogLevel::Health;
      e.component = telemetry::Component::Publishing;
      e.code = telemetry::Code::Drops;
      e.shard = static_cast<uint16_t>(shardId_);
      e.arg0 = deltaLogDrops;
      e.arg1 = totalLogDrops;
      (void)logger_.try_publish(e);
    }

    void maybeLogHealthTick(uint64_t nowNs) noexcept {
      if (nowNs < nextHealthNs_)
        return;
      nextHealthNs_ = nowNs + kHealthEveryNs;

      const uint64_t enq = enqueued_.load(std::memory_order_relaxed);
      const uint64_t pub = published_.load(std::memory_order_relaxed);
      const uint64_t drop = dropped_.load(std::memory_order_relaxed);
      const uint64_t qsz = static_cast<uint64_t>(queue_.size_approx());

      const uint64_t dEnq = enq - lastEnq_;
      const uint64_t dPub = pub - lastPub_;
      const uint64_t dDrop = drop - lastDrop_;

      lastEnq_ = enq;
      lastPub_ = pub;
      lastDrop_ = drop;

      emitHealth(nowNs, qsz, dEnq, dPub);

      if (dDrop > 0) {
        emitDrops(nowNs, dDrop, drop);
        emitQueueSaturated(nowNs, qsz, dDrop, drop);
      }

      const uint64_t logDrop = logger_.dropped();
      const uint64_t dLogDrop = logDrop - lastLogDrop_;
      lastLogDrop_ = logDrop;

      if (dLogDrop > 0)
        emitLogDrops(nowNs, dLogDrop, logDrop);
    }

    void run() noexcept {
      using namespace std::chrono_literals;

      OrdersSnapshot raw{};
      BookSnapshot mbp{};
      std::string outBuffer;
      outBuffer.reserve(512);

      uint64_t nowNs = nowNsSystem();
      nextHealthNs_ = nowNs + kHealthEveryNs;
      lastEnq_ = lastPub_ = lastDrop_ = 0;
      lastLogDrop_ = 0;

      logStartup(nowNs);

      auto publish_one = [&](const OrdersSnapshot &s) {
        aggregateMboWindowToMbpTopN(s, mbp);

        outBuffer.clear();
        mapper_.mapAndSerialize(mbp, outBuffer);

        publishing::PublishEvent ev{};

        ev.size = 0;

        // topic = símbolo humano (o fallback IID:xxxx)
        if (!topicMapper_.tryWriteTopic(s.instrumentId, ev)) {
          dropped_.fetch_add(1, std::memory_order_relaxed);
          return;
        }

        const size_t n = outBuffer.size();
        if (n > publishing::PublishEvent::kMaxBytes) {
          dropped_.fetch_add(1, std::memory_order_relaxed);
          return;
        }

        ev.size = static_cast<uint32_t>(n);
        if (n > 0)
          std::memcpy(ev.bytes, outBuffer.data(), n);

        if (!sink_.tryPublish(shardId_, ev)) {
          dropped_.fetch_add(1, std::memory_order_relaxed);
          return;
        }

        published_.fetch_add(1, std::memory_order_relaxed);
      };

      while (running_.load(std::memory_order_acquire) ||
             (drainOnStop_.load(std::memory_order_relaxed) && queue_.size_approx() > 0)) {
        bool didWork = false;

        while (queue_.try_pop(raw)) {
          didWork = true;
          nowNs = raw.exchangeTsNs; // heartbeat “del feed” cuando hay data
          publish_one(raw);
        }

        if (!didWork) {
          nowNs = nowNsSystem(); // heartbeat “local” cuando está idle
          std::this_thread::sleep_for(1ms);
        }

        maybeLogHealthTick(nowNs);
      }

      logShutdown(nowNs);
    }

   private:
    static constexpr uint64_t kHealthEveryNs = 5'000'000'000ull;

    const uint32_t shardId_;

    SnapshotQueueSpsc<OrdersSnapshot, kQueueCapacity> queue_;

    MdSnapshotMapper &mapper_;
    publishing::IPublishSink &sink_;

    telemetry::SpdlogLogPublisher<kLogQueueCapacity> logger_;

    std::atomic<bool> running_{false};
    std::atomic<bool> drainOnStop_{true};
    std::thread thread_{};

    std::atomic<uint64_t> enqueued_{0};
    std::atomic<uint64_t> dropped_{0};
    std::atomic<uint64_t> published_{0};

    uint64_t nextHealthNs_{0};
    uint64_t lastEnq_{0};
    uint64_t lastPub_{0};
    uint64_t lastDrop_{0};
    uint64_t lastLogDrop_{0};

    const mapping::InstrumentTopicMapper &topicMapper_;
  };

} // namespace b3::md

===== FILE: /workspaces/MarketHub.B3Connector/b3-md-connector/src/core/IOrderBookView.hpp =====
#pragma once
#include <cstdint>

namespace b3::md {

  struct Level {
    int64_t price{0};
    int64_t qty{0};
  };

  class IOrderBookView {
   public:
    virtual ~IOrderBookView() = default;

    virtual uint64_t instrumentId() const noexcept = 0;
    virtual uint64_t exchangeTsNs() const noexcept = 0;

    virtual uint32_t bidCount() const noexcept = 0;
    virtual uint32_t askCount() const noexcept = 0;

    virtual Level bidLevel(uint32_t i) const noexcept = 0;
    virtual Level askLevel(uint32_t i) const noexcept = 0;
  };


===== FILE: /workspaces/MarketHub.B3Connector/b3-md-connector/src/core/BookSnapshot.hpp =====
#pragma once
#include "IOrderBookView.hpp" // o donde esté Level
#include <cstdint>
#include <type_traits>

namespace b3::md {

  template <int N>
  struct BookSnapshotT {
    static constexpr int DEPTH = N;

    uint64_t instrumentId{0};
    uint64_t exchangeTsNs{0};
    uint8_t bidCount{0};
    uint8_t askCount{0};

    Level bids[N]{};
    Level asks[N]{};
  };

  using BookSnapshot = BookSnapshotT<5>;

  static_assert(std::is_trivially_copyable_v<BookSnapshot>);
  static_assert(std::is_trivially_destructible_v<BookSnapshot>);

} // namespace b3::md

===== FILE: /workspaces/MarketHub.B3Connector/b3-md-connector/src/core/OrdersSnapshot.hpp =====
#pragma once

#include <cstdint>
#include <cstddef>
#include <type_traits>

namespace b3::md {

  // Ventana acotada de órdenes (MBO) copiada en hot path.
  // Se agrega (MBO->MBP) en el worker para generar BookSnapshot (niveles de precio).
  //
  // Nota: las órdenes con precio null (market orders) se SALTEAN al copiar,
  // porque no contribuyen al agregado por niveles de precio (MBP).
  struct OrdersSnapshot {
    static constexpr size_t K = 256;

    struct OrderEntry {         // todo:verificar prefision
      int64_t priceMantissa{0}; // precio con 4 decimales (mantissa)
      int64_t qty{0};           // Quantity (Int64)
    };

    uint64_t instrumentId{0};
    uint64_t exchangeTsNs{0};

    // Secuencias del SDK (las copiamos para futuro/protobuf/health)
    uint64_t rptSeq{0};     // OrderBook::lastRptSeq()
    uint64_t channelSeq{0}; // OrderBook::lastMessageSeqNumApplied()

    // Tamaños "crudos" del libro (lo que expone el SDK, sin filtrar null-price)
    uint16_t bidCountRaw{0};
    uint16_t askCountRaw{0};

    // Cantidad efectiva copiada (solo órdenes con precio válido, hasta K)
    uint16_t bidsCopied{0};
    uint16_t asksCopied{0};

    // Flags: 1 si hubo más órdenes válidas que K y se truncó; 0 si entraron todas.
    uint8_t bidTruncated{0};
    uint8_t askTruncated{0};

    OrderEntry bids[K]{};
    OrderEntry asks[K]{};
  };

  static_assert(std::is_trivially_copyable_v<OrdersSnapshot>);
  static_assert(std::is_trivially_destructible_v<OrdersSnapshot>);

} // namespace b3::md

===== FILE: /workspaces/MarketHub.B3Connector/b3-md-connector/src/core/MdPublishPipeline.hpp =====
#pragma once

#include "MdPublishWorker.hpp"
#include "OrdersSnapshot.hpp"

#include <cstdint>
#include <memory>
#include <vector>
#include <atomic>
#include <stdexcept>

namespace b3::md {

// Pipeline = orquestador de sharding + lifecycle de workers.
